{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning of VGG16 for Biofuel Material Cassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras as kr\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import itertools\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation Dependant Globals\n",
    "REQUIRED_DIMENSIONS = (224, 224)\n",
    "TRAIN_BATCH_SIZE  = 10\n",
    "VALIDATION_BATCH_SIZE = 10\n",
    "TEST_BATCH_SIZE = 10\n",
    "\n",
    "# Import dataset\n",
    "%run DataAugmentation.ipynb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetch & Download VGG16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vgg16 = kr.applications.vgg16\n",
    "vgg16_model = vgg16.VGG16(\n",
    "    include_top=False, \n",
    "    weights='imagenet', \n",
    "    input_tensor=kr.layers.Input(shape=REQUIRED_DIMENSIONS+(3,))\n",
    ")\n",
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data from a pretrained model (skip if training)\n",
    "_If running the cell below, skip the build & train phases!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = kr.models.load_model(\"trained_model\")\n",
    "history = []\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building & Compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ease of Access\n",
    "Model, Dropout, Flatten, Dense = kr.models.Model, kr.layers.Dropout, kr.layers.Flatten, kr.layers.Dense\n",
    "\n",
    "# Construct the Head Model\n",
    "head_model = vgg16_model.output\n",
    "head_model = Flatten(name=\"flatten\")(head_model)\n",
    "head_model = Dense(512, activation=\"relu\")(head_model)\n",
    "head_model = Dropout(0.5)(head_model)\n",
    "head_model = Dense(2, activation=\"softmax\")(head_model)\n",
    "\n",
    "# place the head model on top of the base model (this will become the actual model we will train)\n",
    "model = Model(inputs=vgg16_model.input, outputs=head_model)\n",
    "\n",
    "# Freeze all the layers\n",
    "for layer in vgg16_model.layers[:]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Show a summary of the model. Check the number of trainable parameters\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warmup Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Module\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=kr.optimizers.RMSprop(lr=1e-4),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the head of the module (Our Layers)\n",
    "t1_history = model.fit_generator(\n",
    "    train_set,\n",
    "    steps_per_epoch=train_set.samples/train_set.batch_size,\n",
    "    epochs=15,\n",
    "    validation_data=validation_set,\n",
    "    validation_steps=validation_set.samples/validation_set.batch_size,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"warmedupModel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset validaiton & train set generators\n",
    "train_set.reset()\n",
    "validation_set.reset()\n",
    "\n",
    "# Now that the head FC layers have been trained/initialized, lets\n",
    "# Unfreeze the final set of CONV layers and make them trainable\n",
    "for layer in vgg16_model.layers[15:]:\n",
    "\tlayer.trainable = True\n",
    "\n",
    "    \n",
    "# Recompile module for changes to take effect, now using SGD with very small learning rate\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\", \n",
    "    optimizer=kr.optimizers.RMSprop(lr=1e-4), \n",
    "    metrics=[\"accuracy\"]\n",
    ")    \n",
    "\n",
    "# Train the whole module\n",
    "t2_history = model.fit_generator(\n",
    "    train_set,\n",
    "    steps_per_epoch=train_set.samples/train_set.batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=validation_set,\n",
    "    validation_steps=validation_set.samples/validation_set.batch_size,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualising Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_history.plot_title = \"Warmup\"\n",
    "t2_history.plot_title = \"Final\"\n",
    "\n",
    "global_history = [t1_history, t2_history]\n",
    "\n",
    "for history in global_history:\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy'], label='accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.title(\"Accuracy - \" + history.plot_title)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.title(\"Loss - \" + history.plot_title)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making Predictions & Visualising Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(test_set, steps=1, verbose=1)\n",
    "_, test_labels = next(test_set)\n",
    "\n",
    "# get predictions for the test set\n",
    "for i in range(len(test_set)-1):\n",
    "    predictions = np.concatenate((predictions,model.predict_generator(test_set, steps=1, verbose=1)))\n",
    "    _,temp = next(test_set)\n",
    "    test_labels = np.concatenate((test_labels,temp))\n",
    "\n",
    "# get labels from the test set\n",
    "def ReformatData(y):\n",
    "    x = np.copy(y[:,0])\n",
    "    for i in range(len(x)):\n",
    "        if x[i]>=0.5 or x[i] == True:\n",
    "            x[i]=1\n",
    "        else:\n",
    "            x[i]=0\n",
    "    x.astype(int)        \n",
    "    return x\n",
    "                \n",
    "cut_predictions = ReformatData(predictions)\n",
    "cut_labels = ReformatData(test_labels)\n",
    "\n",
    "print(\"Cut predictions:\",cut_predictions)\n",
    "print(\"Cut labels:\",cut_labels)\n",
    "print(\"Unique labels:\",unique_labels(cut_predictions,cut_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = [\"non_biofuel\",\"biofuel\"]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "        \n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    \n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, abs(i-0.25), format(cm[i, j], fmt),\n",
    "                    horizontalalignment=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix based on predictions of our test data set\n",
    "plot_confusion_matrix(cut_labels, cut_predictions, ['biomass', 'non_biomass'], title='Confusion Matrix', normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----------------- Cells Below Are for Testing Purposes ----------------- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### DONT RUN - THIS IS FOR TESTING PURPOSES ########\n",
    "\n",
    "# load the model\n",
    "test_vgg16 = kr.applications.vgg16\n",
    "test_model = test_vgg16.VGG16()\n",
    "# load an image from file\n",
    "test_image = kr.preprocessing.image.load_img('dataset/train/biomass/cardboard189.jpg', target_size=(224, 224))\n",
    "# convert the image pixels to a numpy array\n",
    "test_image = kr.preprocessing.image.img_to_array(test_image)\n",
    "# reshape data for the model\n",
    "test_image = test_image.reshape((1, test_image.shape[0], test_image.shape[1], test_image.shape[2]))\n",
    "# prepare the image for the VGG model\n",
    "test_image = test_vgg16.preprocess_input(test_image)\n",
    "# predict the probability across all output classes\n",
    "yhat = test_model.predict(test_image)\n",
    "# convert the probabilities to class labels\n",
    "tesT_label = test_vgg16.decode_predictions(yhat)\n",
    "# retrieve the most likely result, e.g. highest probability\n",
    "test_label = test_label[0][0]\n",
    "# print the classification\n",
    "print('%s (%.2f%%)' % (test_label[1], test_label[2]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
