{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation & Augementation\n",
    "In this file the dataset is loaded and transformed into all the formats required by the different classification algorithms. When calling this file, **make sure** you have a few global constants set:\n",
    "* REQUIRED_DIMENSIONS\n",
    "* TRAIN_BATCH_SIZE\n",
    "* VALIDATION_BATCH_SIZE \n",
    "* TEST_BATCH_SIZE\n",
    "* N_AUG_VS_TEST\n",
    "\n",
    "In addition, this file creates output constants:\n",
    "* DATASET_ROOT\n",
    "* TRAIN_FOLDER      \n",
    "* VALIDATION_FOLDER \n",
    "* TEST_FOLDER\n",
    "* CLASSES\n",
    "\n",
    "And, output keras generators:\n",
    "* test_set\n",
    "* train_set\n",
    "* valdiation_set\n",
    "* (augmentation versions)\n",
    "\n",
    "And, output raw congregates (all of the dataset together):\n",
    "* Images\n",
    "* rawPixels\n",
    "* Features\n",
    "* Labels\n",
    "* (augmentation versions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and Correct File Usage Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib\n",
    "import time\n",
    "import os\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as aug\n",
    "import tensorflow as tf\n",
    "import matplotlib as mp\n",
    "\n",
    "from matplotlib import pyplot as pp\n",
    "from matplotlib import image as mpimg\n",
    "from tensorflow import keras as kr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not run this file by itself, this variables must be defined\n",
    "# in the file importing this as they are implementation dependant\n",
    "try:\n",
    "    (REQUIRED_DIMENSIONS \n",
    "         or TRAIN_BATCH_SIZE \n",
    "         or VALIDATION_BATCH_SIZE \n",
    "         or TEST_BATCH_SIZE\n",
    "         or N_AUG_VS_TEST)\n",
    "except NameError:\n",
    "    raise Exception('One of the required global constants is missing.\\n -> Do not run this file by itself?')\n",
    "\n",
    "# Implementation independent globals\n",
    "DATASET_ROOT      = './dataset/'\n",
    "TRAIN_FOLDER      = 'train'\n",
    "VALIDATION_FOLDER = 'validation'\n",
    "TEST_FOLDER       = 'test'\n",
    "CLASSES           = ['biomass', 'non_biomass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "lib.log(\"Data preparation started.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies the given augmenter in 35% of all cases,\n",
    "sometimes = lambda a: aug.Sometimes(0.35, a)\n",
    "\n",
    "# Augmentations applied to the training set\n",
    "# More information: https://github.com/aleju/imgaug\n",
    "seq = aug.Sequential([\n",
    "    # Crop images from each side by 0 to 16px (randomly chosen)\n",
    "    aug.Crop(px=(0, 16)),\n",
    "    # Horizontally all of the images\n",
    "    aug.Fliplr(1),\n",
    "    # vertically flip 50% of the images\n",
    "    aug.Flipud(0.5),\n",
    "    # Multiple changes (sometimes)\n",
    "    sometimes(aug.Affine(\n",
    "        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}, # scale images to 80-120% of their size, individually per axis\n",
    "        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}, # translate by -20 to +20 percent (per axis)\n",
    "        rotate=(-45, 45), # rotate by -45 to +45 degrees\n",
    "        shear=(-16, 16), # shear by -16 to +16 degrees\n",
    "        order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n",
    "        cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n",
    "        mode=ia.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
    "    )),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(img):\n",
    "    seq_det = seq.to_deterministic()\n",
    "    aug_image = seq_det.augment_image(img)\n",
    "\n",
    "    return aug_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_feature_vector(image, size=REQUIRED_DIMENSIONS):\n",
    "\t# resize the image to a fixed size, then flatten the image into\n",
    "\t# a list of raw pixel intensities\n",
    "\treturn cv2.resize(image, size).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_color_histogram(image, bins=(8, 8, 8)):\n",
    "\t# extract a 3D color histogram from the HSV color space using\n",
    "\t# the supplied number of `bins` per channel\n",
    "\thsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\thist = cv2.calcHist([hsv], [0, 1, 2], None, bins,\n",
    "\t\t[0, 180, 0, 256, 0, 256])\n",
    " \n",
    "\t# handle normalizing the histogram if we are using OpenCV 2.4.X\n",
    "\tif imutils.is_cv2():\n",
    "\t\thist = cv2.normalize(hist)\n",
    " \n",
    "\t# otherwise, perform \"in place\" normalization in OpenCV 3 (I\n",
    "\t# personally hate the way this is done\n",
    "\telse:\n",
    "\t\tcv2.normalize(hist, hist)\n",
    " \n",
    "\t# return the flattened histogram as the feature vector\n",
    "\treturn hist.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib.log(\"Loaded custom functions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Existing Dataset & Perform Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Congregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Congregate\n",
    "Images = [] # All the images (train, test, validation)\n",
    "rawPixels = [] # Flattened pixel intensities of 'Images'\n",
    "Features = [] # Feature extractions from 'Images'\n",
    "Labels = [] # Labels for all the above.\n",
    "\n",
    "# Augmentations bersions\n",
    "augmented_Images = []\n",
    "augmented_rawPixels = []\n",
    "augmented_Features = []\n",
    "augmented_Labels = []\n",
    "\n",
    "for setName in os.listdir(DATASET_ROOT):\n",
    "    setPath = DATASET_ROOT + setName\n",
    "    for className in os.listdir(setPath):\n",
    "        classPath = setPath + \"/\" + className\n",
    "        for imageName in os.listdir(classPath):\n",
    "            imagePath = classPath + \"/\" + imageName\n",
    "            # Load the image and extract the class label (assuming that our\n",
    "            # Path as the format: /path/to/dataset/{class}.{image_num}.jpg\n",
    "            image = cv2.imread(imagePath)\n",
    "            label = className\n",
    "            \n",
    "            # Check if the image is valid!\n",
    "            if not hasattr(image, \"__len__\"):\n",
    "                print(\"(SKIPPED) Found a non image file: \", imagePath)\n",
    "                continue\n",
    "            \n",
    "            # Extract raw pixel intensity \"features\", followed by a color\n",
    "            # Histogram to characterize the color distribution of the pixels in the image\n",
    "            pixels = image_to_feature_vector(image)\n",
    "            hist = extract_color_histogram(image)\n",
    "\n",
    "            # Update the raw images, features, and labels matricies respectively\n",
    "            Images.append(image)\n",
    "            rawPixels.append(pixels)\n",
    "            Features.append(hist)\n",
    "            Labels.append(label)\n",
    "            \n",
    "            # Do the same, but for augmentation\n",
    "            image = augment(image)\n",
    "            pixels = image_to_feature_vector(image)\n",
    "            hist = extract_color_histogram(image)\n",
    "            \n",
    "            # Update augmentation storages\n",
    "            augmented_Images.append(image)\n",
    "            augmented_rawPixels.append(pixels)\n",
    "            augmented_Features.append(hist)\n",
    "            augmented_Labels.append(label)\n",
    "            \n",
    "\n",
    "# Make numpy arrays, because more useful\n",
    "Images = np.array(Images)\n",
    "rawPixels = np.array(rawPixels)\n",
    "Features = np.array(Features)\n",
    "Labels = np.array(Labels)\n",
    "\n",
    "# Same for augmentations\n",
    "augmented_Images = np.array(augmented_Images)\n",
    "augmented_rawPixels = np.array(augmented_rawPixels)\n",
    "augmented_Features = np.array(augmented_Features)\n",
    "augmented_Labels = np.array(augmented_Labels)\n",
    "\n",
    "# Display some useful information\n",
    "print(\"[Non Augmented Images]\")\n",
    "print(\"\\t - Number of images in total: \" + str(len(Images)))\n",
    "print(\"\\t - Raw pixels matrix: {:.2f}MB\".format(rawPixels.nbytes / (1024 * 1000.0)))\n",
    "print(\"\\t - Raw features matrix: {:.2f}MB\".format(Features.nbytes / (1024 * 1000.0)))\n",
    "\n",
    "# Same for augmentations\n",
    "print(\"[Augmented Images]\")\n",
    "print(\"\\t - Number of images in total: \" + str(len(augmented_Images)))\n",
    "print(\"\\t - Raw pixels matrix: {:.2f}MB\".format(augmented_rawPixels.nbytes / (1024 * 1000.0)))\n",
    "print(\"\\t - Raw features matrix: {:.2f}MB\".format(augmented_Features.nbytes / (1024 * 1000.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib.log(\"Loaded raw congregates of images, features and labels.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Keras Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Shortcut\n",
    "IDG = kr.preprocessing.image.ImageDataGenerator\n",
    "\n",
    "# No augmentation\n",
    "generator = IDG()\n",
    "\n",
    "# Augmentation\n",
    "agumented_generator = IDG(preprocessing_function=augment)\n",
    "\n",
    "print(\"[Non Augmented Generators]\")\n",
    "\n",
    "# Iterator for training data set\n",
    "train_set = generator.flow_from_directory(\n",
    "    DATASET_ROOT + TRAIN_FOLDER, \n",
    "    target_size=REQUIRED_DIMENSIONS, \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Iterator for validation data set\n",
    "validation_set = generator.flow_from_directory(\n",
    "    DATASET_ROOT + VALIDATION_FOLDER, \n",
    "    target_size=REQUIRED_DIMENSIONS, \n",
    "    batch_size=VALIDATION_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Iterator for test data set\n",
    "test_set = generator.flow_from_directory(\n",
    "    DATASET_ROOT + TEST_FOLDER, \n",
    "    target_size=REQUIRED_DIMENSIONS, \n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ");\n",
    "\n",
    "print(\"[Augmented Generators]\")\n",
    "\n",
    "# Iterator for augmented training data set\n",
    "augmented_train_set = agumented_generator.flow_from_directory(\n",
    "    DATASET_ROOT + TRAIN_FOLDER, \n",
    "    target_size=REQUIRED_DIMENSIONS, \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Iterator for augmented training data set\n",
    "augmented_test_set = agumented_generator.flow_from_directory(\n",
    "    DATASET_ROOT + TEST_FOLDER, \n",
    "    target_size=REQUIRED_DIMENSIONS, \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Iterator for augmented training data set\n",
    "augmented_validation_set = agumented_generator.flow_from_directory(\n",
    "    DATASET_ROOT + VALIDATION_FOLDER, \n",
    "    target_size=REQUIRED_DIMENSIONS, \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib.log(\"Loaded all generators.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib.log(\"Data preperation completed!\\nTime taken: \" + str(time.time() - start_time) + \" seconds.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
