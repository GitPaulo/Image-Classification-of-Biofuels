{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation & Augementation\n",
    "In this file the dataset is loaded and transformed into all the formats required by the different classification algorithms. When calling this file, **make sure** you have a few global constants set:\n",
    "* REQUIRED_DIMENSIONS\n",
    "* TRAIN_BATCH_SIZE\n",
    "* VALIDATION_BATCH_SIZE \n",
    "* TEST_BATCH_SIZE\n",
    "* N_AUG_VS_TEST\n",
    "\n",
    "In addition, this file creates output constants:\n",
    "* DATASET_ROOT\n",
    "* TRAIN_FOLDER      \n",
    "* VALIDATION_FOLDER \n",
    "* TEST_FOLDER\n",
    "* CLASSES\n",
    "\n",
    "And, output keras generators:\n",
    "* test_set\n",
    "* train_set\n",
    "* valdiation_set\n",
    "* (+ augmentated_ and non_augmented versions)\n",
    "\n",
    "And, output shuffled congregates:\n",
    "* pixels\n",
    "* pixels_labels\n",
    "* features\n",
    "* features_labels\n",
    "\n",
    "And, output dataset numpy data:\n",
    "* non_augmented_images\n",
    "* non_augmented_pixels \n",
    "* non_augmented_features\n",
    "* non_augmented_labels\n",
    "* augmented_images\n",
    "* augmented_pixels\n",
    "* augmented_features\n",
    "* augmented_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and Correct File Usage Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib\n",
    "import time\n",
    "import os\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as aug\n",
    "import tensorflow as tf\n",
    "import matplotlib as mp\n",
    "\n",
    "from matplotlib import pyplot as pp\n",
    "from matplotlib import image as mpimg\n",
    "from tensorflow import keras as kr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not run this file by itself, this variables must be defined\n",
    "# in the file importing this as they are implementation dependant\n",
    "try:\n",
    "    (REQUIRED_DIMENSIONS \n",
    "         or TRAIN_BATCH_SIZE \n",
    "         or VALIDATION_BATCH_SIZE \n",
    "         or TEST_BATCH_SIZE\n",
    "         or N_AUG_VS_TEST)\n",
    "except NameError:\n",
    "    raise Exception('One of the required global constants is missing.\\n -> Do not run this file by itself?')\n",
    "\n",
    "# Implementation independent globals\n",
    "DATASET_ROOT      = './dataset/'\n",
    "TRAIN_FOLDER      = 'train'\n",
    "VALIDATION_FOLDER = 'validation'\n",
    "TEST_FOLDER       = 'test'\n",
    "CLASSES           = ['biomass', 'non_biomass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "lib.log(\"Data preparation started.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies the given augmenter in 35% of all cases,\n",
    "sometimes = lambda a: aug.Sometimes(0.35, a)\n",
    "\n",
    "# Augmentations applied to the training set\n",
    "# More information: https://github.com/aleju/imgaug\n",
    "seq = aug.Sequential([\n",
    "    # Crop images from each side by 0 to 16px (randomly chosen)\n",
    "    aug.Crop(px=(0, 16)),\n",
    "    # Horizontally all of the images\n",
    "    aug.Fliplr(1),\n",
    "    # vertically flip 50% of the images\n",
    "    aug.Flipud(0.5),\n",
    "    # Multiple changes (sometimes)\n",
    "    sometimes(aug.Affine(\n",
    "        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}, # scale images to 80-120% of their size, individually per axis\n",
    "        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}, # translate by -20 to +20 percent (per axis)\n",
    "        rotate=(-45, 45), # rotate by -45 to +45 degrees\n",
    "        shear=(-16, 16), # shear by -16 to +16 degrees\n",
    "        order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n",
    "        cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n",
    "        mode=ia.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
    "    )),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(img):\n",
    "    seq_det = seq.to_deterministic()\n",
    "    aug_image = seq_det.augment_image(img)\n",
    "\n",
    "    return aug_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_feature_vector(image, size=REQUIRED_DIMENSIONS):\n",
    "\t# resize the image to a fixed size, then flatten the image into\n",
    "\t# a list of raw pixel intensities\n",
    "\treturn cv2.resize(image, size).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_color_histogram(image, bins=(8, 8, 8)):\n",
    "\t# extract a 3D color histogram from the HSV color space using\n",
    "\t# the supplied number of `bins` per channel\n",
    "\thsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\thist = cv2.calcHist([hsv], [0, 1, 2], None, bins,\n",
    "\t\t[0, 180, 0, 256, 0, 256])\n",
    " \n",
    "\t# handle normalizing the histogram if we are using OpenCV 2.4.X\n",
    "\tif imutils.is_cv2():\n",
    "\t\thist = cv2.normalize(hist)\n",
    " \n",
    "\t# otherwise, perform \"in place\" normalization in OpenCV 3 (I\n",
    "\t# personally hate the way this is done\n",
    "\telse:\n",
    "\t\tcv2.normalize(hist, hist)\n",
    " \n",
    "\t# return the flattened histogram as the feature vector\n",
    "\treturn hist.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib.log(\"Loaded custom functions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Existing Dataset & Perform Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Congregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Congregates\n",
    "pixels = [] # Flattened pixel intensities of 'Images'\n",
    "pixels_labels = [] # Labels for the above\n",
    "features = [] # Feature extractions from 'Images'\n",
    "features_labels = [] # Labels for the above\n",
    "\n",
    "# Non augmentated versions\n",
    "non_augmented_images = [] \n",
    "non_augmented_pixels = [] \n",
    "non_augmented_features = [] \n",
    "non_augmented_labels = [] \n",
    "\n",
    "# Augmentation versions\n",
    "augmented_images = []\n",
    "augmented_pixels = []\n",
    "augmented_features = []\n",
    "augmented_labels = []\n",
    "\n",
    "for setName in os.listdir(DATASET_ROOT):\n",
    "    setPath = DATASET_ROOT + setName\n",
    "    for className in os.listdir(setPath):\n",
    "        classPath = setPath + \"/\" + className\n",
    "        for imageName in os.listdir(classPath):\n",
    "            imagePath = classPath + \"/\" + imageName\n",
    "            # Load the image and extract the class label (assuming that our\n",
    "            # Path as the format: /path/to/dataset/{class}.{image_num}.jpg\n",
    "            image = cv2.imread(imagePath)\n",
    "            \n",
    "            # Check if the image is valid!\n",
    "            if not hasattr(image, \"__len__\"):\n",
    "                print(\"(SKIPPED) Found a non image file: \", imagePath)\n",
    "                continue\n",
    "            \n",
    "            # Augment image\n",
    "            aug_image = augment(image)\n",
    "            \n",
    "            # Extract raw pixel intensity \"features\", followed by a color\n",
    "            # Histogram to characterize the color distribution of the pixels in the image\n",
    "            pixels = image_to_feature_vector(image)\n",
    "            hist = extract_color_histogram(image)\n",
    "            aug_pixels = image_to_feature_vector(aug_image)\n",
    "            aug_hist = extract_color_histogram(aug_image)\n",
    "            \n",
    "            # Sort the label (All the same label)\n",
    "            label = className\n",
    "            non_augmented_labels.append(label)\n",
    "            augmented_labels.append(label)\n",
    "           \n",
    "            # Sort the image\n",
    "            non_augmented_images.append(image)\n",
    "            augmented_images.append(aug_image)\n",
    "            \n",
    "            # Sort the raw pixel\n",
    "            non_augmented_pixels.append(pixels)\n",
    "            augmented_pixels.append(aug_pixels)\n",
    "            \n",
    "            # Sort the historgram\n",
    "            non_augmented_features.append(hist)\n",
    "            augmented_features.append(aug_hist)\n",
    "\n",
    "# Numpy arrays more useful\n",
    "non_augmented_images = np.array(non_augmented_images)\n",
    "non_augmented_pixels = np.array(non_augmented_pixels)\n",
    "non_augmented_features = np.array(non_augmented_features)\n",
    "non_augmented_labels = np.array(non_augmented_labels)\n",
    "\n",
    "# Same for augmentations\n",
    "augmented_images = np.array(augmented_images)\n",
    "augmented_pixels = np.array(augmented_pixels)\n",
    "augmented_features = np.array(augmented_features)\n",
    "augmented_labels = np.array(augmented_labels)\n",
    "\n",
    "# Build Congregates: Raw Pixels\n",
    "pixels, pixels_labels = lib.shuffleJoinRawDatasets(\n",
    "    non_augmented_pixels, non_augmented_labels, \n",
    "    augmented_pixels, augmented_labels\n",
    ")\n",
    "\n",
    "# Build Congregates: Features\n",
    "features, features_labels = lib.shuffleJoinRawDatasets(\n",
    "    non_augmented_features, non_augmented_labels, \n",
    "    augmented_features, augmented_labels\n",
    ")\n",
    "\n",
    "# Display some useful information\n",
    "print(\"[Non Processed Classifier Input Data]\")\n",
    "print(\"Raw pixels matrix: {:.2f}MB\".format(pixels.nbytes / (1024 * 1000.0)))\n",
    "print(\"Raw features matrix: {:.2f}MB\".format(features.nbytes / (1024 * 1000.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib.log(\"Loaded raw congregates of images, features and labels.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Keras Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Shortcut\n",
    "IDG = kr.preprocessing.image.ImageDataGenerator\n",
    "\n",
    "# No augmentation\n",
    "generator = IDG()\n",
    "\n",
    "# Augmentation\n",
    "agumented_generator = IDG(preprocessing_function=augment)\n",
    "\n",
    "print(\"[Non Augmented Generators]\")\n",
    "\n",
    "# Iterator for training data set\n",
    "non_augmented_train_set = generator.flow_from_directory(\n",
    "    DATASET_ROOT + TRAIN_FOLDER, \n",
    "    target_size=REQUIRED_DIMENSIONS, \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Iterator for validation data set\n",
    "non_augmented_validation_set = generator.flow_from_directory(\n",
    "    DATASET_ROOT + VALIDATION_FOLDER, \n",
    "    target_size=REQUIRED_DIMENSIONS, \n",
    "    batch_size=VALIDATION_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Iterator for test data set\n",
    "non_augmented_test_set = generator.flow_from_directory(\n",
    "    DATASET_ROOT + TEST_FOLDER, \n",
    "    target_size=REQUIRED_DIMENSIONS, \n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ");\n",
    "\n",
    "print(\"[Augmented Generators]\")\n",
    "\n",
    "# Iterator for augmented training data set\n",
    "augmented_train_set = agumented_generator.flow_from_directory(\n",
    "    DATASET_ROOT + TRAIN_FOLDER, \n",
    "    target_size=REQUIRED_DIMENSIONS, \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Iterator for augmented validation data set\n",
    "augmented_validation_set = agumented_generator.flow_from_directory(\n",
    "    DATASET_ROOT + VALIDATION_FOLDER, \n",
    "    target_size=REQUIRED_DIMENSIONS, \n",
    "    batch_size=VALIDATION_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Iterator for augmented test data set\n",
    "augmented_test_set = agumented_generator.flow_from_directory(\n",
    "    DATASET_ROOT + TEST_FOLDER, \n",
    "    target_size=REQUIRED_DIMENSIONS, \n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Combined versions\n",
    "train_set = lib.CombinedGenerator(non_augmented_train_set, augmented_train_set)\n",
    "validation_set = lib.CombinedGenerator(non_augmented_validation_set, augmented_validation_set)\n",
    "test_set = lib.CombinedGenerator(non_augmented_test_set, augmented_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib.log(\"Loaded all generators.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[Total Info]\")\n",
    "print(\"Number of images: \" + str(len(pixels)))\n",
    "print(\"Size of images: {:.2f}MB\".format((non_augmented_images.nbytes + augmented_images.nbytes) / (1024 * 1000.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib.log(\"Data preperation completed!\\nTime taken: \" + str(time.time() - start_time) + \" seconds.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
